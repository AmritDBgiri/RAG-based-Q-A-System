# ğŸ” RAG-based Q&A System (LangChain + FAISS + OpenAI)

This project is a **Retrieval-Augmented Generation (RAG)** pipeline built with **LangChain**, **FAISS**, and **OpenAI**.  

It allows you to chat with your **local documents** (`.pdf`, `.txt`) by:
- ğŸ“‚ Running a one-time **ingestion script** to index documents  
- ğŸ’¬ Asking questions via a simple **Streamlit UI**  
- ğŸ’» Using a **CLI tool** for quick terminal queries  

âœ… Tested with **Python 3.10 / 3.11** on Linux & Windows.

---

## âš™ï¸ Setup

```bash
# 1. Create a virtual environment
python -m venv .venv

# 2. Activate it
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Copy environment variables template
cp .env.example .env
# Then open .env and paste your OpenAI API key
ğŸ‘‰ Donâ€™t have an OpenAI key?
You can adapt the code to use a local model (e.g., Ollama / Llama.cpp) by swapping ChatOpenAI for a local LLM wrapper.

ğŸ“‚ Add Documents
Place your source files in the data/ folder. Supported formats:

ğŸ“‘ .pdf (via PyPDFLoader)

ğŸ“„ .txt (via TextLoader)

An example file data/sample.txt is already included.

ğŸ—ï¸ Build the Vector Index (FAISS)
bash
Copy code
python ingest.py
This will create/update the FAISS index under index/ using text-embedding-3-small.

ğŸ’¬ Run the Q&A App (Streamlit)
bash
Copy code
streamlit run app.py
Open the local URL shown in the terminal (e.g., http://localhost:8501)

Ask questions about your docs

Optionally toggle â€œShow retrieved chunksâ€ to inspect retrievals

âš¡ Quick CLI Query (Optional)
bash
Copy code
python query.py "What is this project about?"
ğŸ“‚ Project Structure
graphql
Copy code
rag_faiss_langchain/
â”œâ”€ app.py           # Streamlit Q&A app
â”œâ”€ ingest.py        # Build/update FAISS index
â”œâ”€ query.py         # CLI for quick queries
â”œâ”€ requirements.txt
â”œâ”€ .env.example     # Template for secrets
â”œâ”€ data/            # Your PDFs/TXT here
â”‚  â””â”€ sample.txt
â””â”€ index/           # Auto-generated FAISS index
ğŸ“ Notes & Tips
Use the same embedding model for both indexing & querying

Tune chunk_size and chunk_overlap in ingest.py

Adjust retriever k (number of top chunks) in app.py

Customize prompts in app.py for domain-specific Q&A

ğŸ§ª Evaluation Ideas
Create a small YAML/JSON of Q&A pairs and compare answers (semantic overlap / keyword match)

Track latency and retrieval relevance

ğŸ› ï¸ Troubleshooting
If FAISS throws a warning â†’ keep allow_dangerous_deserialization=True in app.py

For complex PDFs, consider preprocessing or using Unstructured loaders

âœ¨ This project is designed for quick onboarding into RAG pipelines and showcases skills in:

Agentic AI workflows

LangChain orchestration

FAISS vector search

Prompt engineering & debugging








